// Generated by CoffeeScript 1.4.0
(function() {
  var Lexer, d, lex, parse, parseTokens, parser, recurser,
    __slice = [].slice;

  parser = require('../lib/parser').parser;

  Lexer = require("./humon_lexer.coffee").Lexer;

  recurser = require("./json2humon").recurser;

  /*
  # This file is the single point of entry for other libraries.
  # It combines the lexer ('humon_lexer.coffee')
  #
  */


  d = function() {
    var args;
    args = 1 <= arguments.length ? __slice.call(arguments, 0) : [];
    if (typeof $debug !== "undefined" && $debug !== null) {
      console.log(args);
    }
    return args;
  };

  parser.lexer = {
    lex: function() {
      var tag, _ref;
      _ref = this.tokens[this.pos++] || [''], tag = _ref[0], this.yytext = _ref[1], this.yylineno = _ref[2];
      return tag;
    },
    setInput: function(tokens) {
      this.tokens = tokens;
      return this.pos = 0;
    },
    upcomingInput: function() {
      return "";
    }
  };

  parse = function(code) {
    var tokens;
    tokens = lex(code);
    d("##### input code: #####");
    d(code);
    d("\n\n");
    d("##### input tokens: #####");
    d(tokens);
    d("\n\n");
    d("##### parsing: #####");
    return parser.parse(tokens);
  };

  lex = function(code) {
    var lexer;
    lexer = new Lexer();
    return lexer.tokenize(code);
  };

  parseTokens = function(tokens) {
    return parser.parse(tokens);
  };

  if (typeof exports !== "undefined" && exports !== null) {
    exports.lex = lex;
    exports.parseTokens = parseTokens;
    exports.parse = parse;
    exports.d = d;
    exports.json2humon = recurser.json2humon;
  }

  if (typeof window !== "undefined" && window !== null) {
    window.humon = {};
    window.humon.lex = lex;
    window.humon.parseTokens = parseTokens;
    window.humon.parse = parse;
    window.humon.d = d;
    window.humon.json2humon = recurser.json2humon;
  }

}).call(this);
